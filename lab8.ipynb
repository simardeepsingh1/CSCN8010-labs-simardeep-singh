{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Lab 8\n",
    "## Student Name: `Simardeep Singh`\n",
    "## Student Roll Number:`8976948`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dear Professor,\n",
    "#### Welcome to Lab 8 - fMNIST Classification with Dense Neural Networks using Tensorflow\n",
    "\n",
    "In this lab i am focusing on exploring the Fashion MNIST (fMNIST) dataset, training a neural network, and evaluating its performance. Key objectives include a thorough Exploratory Data Analysis (EDA), defining and training a neural network, and assessing the model on both validation and test sets.\n",
    "\n",
    "#### `Lab Objectives:`\n",
    "\n",
    "1. **EDA:** Conducting a concise and insightful Exploratory Data Analysis on Kaggle [data](https://www.kaggle.com/code/abhishekyana/fmnist-dataset-with-cnns-tensorflow).\n",
    "\n",
    "2. **Define and Train Neural Network:** Implementing a fully-connected feedforward neural network using Keras and Tensorflow.\n",
    "\n",
    "3. **Evaluate Model Performance:** Utilizing scikit-learn metrics to evaluate the model on the validation dataset.\n",
    "\n",
    "4. **Test Set Evaluation** Running the trained model on the test set and draw clear conclusions about its performance.\n",
    "\n",
    "5. **Precision and Recall Enhancement:** Exploring code examples to adjust precision and recall for class '5' without model retraining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q1 Get the data from Kaggle. See image below. Tip: load the data into numpy arrays, similar to the MNIST data used in our tutorial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "train_data = pd.read_csv('C:\\\\Foundations_of_Machine_Learning_Frameworks_lab\\\\Labs\\\\lab1\\\\CSCN8010-labs-simardeep-singh\\\\data\\\\fashion mnist\\\\fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('C:\\\\Foundations_of_Machine_Learning_Frameworks_lab\\\\Labs\\\\lab1\\\\CSCN8010-labs-simardeep-singh\\data\\\\fashion mnist\\\\fashion-mnist_test.csv')\n",
    "\n",
    "# Extract features (X) and labels (y) for training data\n",
    "X = train_data.drop('label', axis=1).values\n",
    "y = train_data['label'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q2 Run Great EDA (1 point). For inspiration see the image-specific EDA at the bottom of this notebook (feel free to copy relevant code. This was taken from notebooks of students of this course). Also, feel free to reference code from Kaggle (add links). Important: make it clear for a reader, make it relevant for the problem statement, draw relevant insights.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####     `Check the data types`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Data Type: {type(X_train)}, Labels Type: {type(y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Display keys and shapes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Data Shape: {X_train.shape}')\n",
    "print(f'Target Shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Visualize sample images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(1, 10):\n",
    "    plt.subplot(3, 3, i)\n",
    "    plot_digit(X_train[i])\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Pixel distribution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_train[0], bins=50, range=(0, 255), density=True, alpha=0.5, color='b', label='Original')\n",
    "plt.hist(X_train_gray[0], bins=50, range=(0, 255), density=True, alpha=0.5, color='r', label='Gray Scale')\n",
    "plt.legend()\n",
    "plt.title('Pixel Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Average image per class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.unique(y_train)\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    class_images = X_train[y_train == label]\n",
    "    average_image = np.mean(class_images, axis=0)\n",
    "    plot_digit(average_image)\n",
    "    plt.title(f\"Class {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Lable distribution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(y_train, bins=10, edgecolor='black')\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Pixel intensity distribution for each class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    class_images = X_train[y_train == label]\n",
    "    pixel_intensity = np.mean(class_images, axis=0)\n",
    "    plt.plot(pixel_intensity, label=f'Class {label}')\n",
    "    plt.title(f\"Class {label}\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q3 Define and Train a fully-connected feedforward neural network of your choice using Keras and Tensorflow.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize pixel values\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# Split the data into training and temporary sets (80% training, 20% temporary)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Split the temporary data into validation and test sets (50% validation, 50% test from the temporary set)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# Define the model using Sequential API\n",
    "model = keras.Sequential([\n",
    "  layers.Flatten(input_shape=(X_train.shape[1],)),  # Flatten input\n",
    "  layers.Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation\n",
    "  layers.Dense(64, activation='relu'),  # Second hidden layer with 64 neurons and ReLU activation\n",
    "  layers.Dense(10, activation='softmax')   # Output layer with 10 neurons (fashion categories) and softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model, specifying optimizer, loss function, and metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q4 Evaluate the model using the validation dataset. You can use the same sklearn functions used in lab 7 (accuracy, precision, recall, F1). Feel free to expand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the validation set\n",
    "y_val_prob = model.predict(X_val)\n",
    "y_val_pred = y_val_prob.argmax(axis=-1)\n",
    "\n",
    "# Convert predictions to integers (if needed)\n",
    "y_val_pred = y_val_pred.astype(int)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q5 Run the model on the test set, and provide clear and relevant conclusions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_normalized, y_test)\n",
    "\n",
    "# Print the test loss and accuracy\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CONCLUSION`\n",
    "##### The model's performance on the test set is suboptimal, with an accuracy of approximately 13.93% and a high loss of 2.30. This suggests that the model struggles to generalize well to unseen data.\n",
    "\n",
    "1. **Low Accuracy:** The accuracy of 13.93% indicates that the model is making correct predictions for a small portion of the test samples. In a multiclass classification task, this performance is significantly below what would be expected from a well-performing model.\n",
    "\n",
    "2. **High Loss:** The loss value of 2.30 is quite high, suggesting a lack of confidence in the model's predictions. This could be due to the model providing output probabilities that are not well-calibrated or indicative of clear distinctions between classes.\n",
    "\n",
    "##### The model may be suffering from issues such as overfitting, underfitting, or an insufficiently complex architecture as well as  preprocessing or normalization of the data might be impacting on performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q6 What if we wanted to increase the precision for class '5', how can we do that without changing the model or retraining? provide code that exemplifies this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_threshold = 0.1  \n",
    "class_5_predicted_labels = (class_5_probabilities >= new_threshold).astype(int)\n",
    "\n",
    "# Calculating precision for class 5 with the new threshold\n",
    "precision_class_5_new = precision_score(y_test == 5, class_5_predicted_labels)\n",
    "\n",
    "print(f'Precision for class 5 with the new threshold: {precision_class_5_new}')\n",
    "print(f'New threshold: {new_threshold}')\n",
    "\n",
    "# precision-recall curve with new thhreshold for precision\n",
    "precision, recall, thresholds = precision_recall_curve(y_test == 5, class_5_probabilities)\n",
    "\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for Class 5 with New Threshold for Precision')\n",
    "plt.axhline(y=precision_class_5_new, color='r', linestyle='--', label=f'Precision (New Threshold): {precision_class_5_new:.4f}')\n",
    "plt.axvline(x=np.sum(y_test == 5) / len(y_test), color='b', linestyle='--', label='Random Baseline')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `In summary, adjusting the threshold for class '5' in the model significantly impacted precision. By lowering the threshold from the default value, we increased the number of instances predicted as class '5', resulting in a higher rate of false positives.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q7 What if we wanted to increase the recall for class '5', how can we do that without changing the model or retraining? provide code that exemplifies this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recall_threshold = 0.1\n",
    "\n",
    "class_5_predicted_labels_high_recall = (class_5_probabilities >= new_recall_threshold).astype(int)\n",
    "\n",
    "# Calculating recall for class 5\n",
    "recall_class_5_high_recall = recall_score(y_test == 5, class_5_predicted_labels_high_recall)\n",
    "\n",
    "print(f'Recall for class 5 with the new threshold for recall: {recall_class_5_high_recall}')\n",
    "print(f'New threshold for recall: {new_recall_threshold}')\n",
    "\n",
    "# precision-recall curve with the new threshold for recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_test == 5, class_5_probabilities)\n",
    "\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for Class 5 with New Threshold for Recall')\n",
    "plt.axvline(x=recall_class_5_high_recall, color='g', linestyle='--', label=f'Recall (New Threshold): {recall_class_5_high_recall:.4f}')\n",
    "plt.axhline(y=precision[recall >= new_recall_threshold].max(), color='r', linestyle='--', label=f'Max Precision at New Recall Threshold: {precision[recall >= new_recall_threshold].max():.4f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `In Summary, I adjusted the threshold for class '5' to enhance the recall performance without retraining the model. By setting a new threshold of 0.1, I achieved a recall of approximately 0.0988. This adjustment allowed us to prioritize the identification of true positive instances of class '5' at the expense of potentially higher false positives.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
